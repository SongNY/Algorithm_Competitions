{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2, 3, 4\"\n",
    "import logging\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "# logging.basicConfig(level=logging.INFO, filename='log_Model', format=LOG_FORMAT)\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "def show_df(df):\n",
    "    display(HTML(df.to_html()))\n",
    "    \n",
    "VAL_POINT = 65623"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = '../user_data/build_dataset/df_train_info.pickle'\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    df_train_info = pickle.load(f)\n",
    "\n",
    "pickle_path = '../user_data/build_dataset/df_testA_info.pickle'\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    df_testA_info = pickle.load(f)\n",
    "\n",
    "pickle_path = '../user_data/build_dataset/df_testB_info.pickle'\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    df_testB_info = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_arugment_data_train():\n",
    "    part = 32\n",
    "    len_key_list = 82533\n",
    "    \n",
    "    df_feature_train_list = []\n",
    "    for i in range(0, len_key_list, int(len_key_list / part)):\n",
    "        start, end = i, i + int(len_key_list / part)\n",
    "        end = min(end, len_key_list)\n",
    "        pickle_path = '../user_data/df_feature_train/df_feature_train_%d_%d.pickle' % (start, end)\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            df_feature_train_part = pickle.load(f)\n",
    "            df_feature_train_part['origin_i'] += start\n",
    "            df_feature_train_list.append(df_feature_train_part)\n",
    "    df_features_train = pd.concat(df_feature_train_list)\n",
    "    df_features_train = df_features_train.sort_values(by = ['origin_i', 'know_lens', 'target_position',])\n",
    "    df_features_train.index = range(df_features_train.shape[0])\n",
    "    \n",
    "    return df_features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_train_arugment = read_arugment_data_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = '../user_data/df_feature_test/df_features_testB.pickle'\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    df_features_testB = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 08:19:46,598 - INFO - origin feature lens: 118\n",
      "2020-04-14 08:19:46,601 - INFO - start building se_pairs\n",
      "2020-04-14 08:23:18,466 - INFO - finish building origin train\n",
      "2020-04-14 08:44:07,315 - INFO - finish building train arugment\n",
      "2020-04-14 08:49:05,132 - INFO - finish building se_pairs\n"
     ]
    }
   ],
   "source": [
    "weight_names = []\n",
    "pass_names = []\n",
    "all_agg_names = []\n",
    "for name in df_features_train_arugment.columns:\n",
    "    if '_weight' in name:\n",
    "        weight_names.append(name)\n",
    "    if 'pass_agg' in name:\n",
    "        pass_names.append(name)\n",
    "    if 'all_agg' in name:\n",
    "        all_agg_names.append(name)\n",
    "\n",
    "        \n",
    "not_features = ['origin_i', 'target_position', 'start_action_expect_time', 'last_action_expect_time', 'cur_action_expect_time',\n",
    "                'last_action_time_hour', 'last_action_time_minute', 'last_action_time_second', 'last_action_time_weekday', \n",
    "                'last_action_time_is_weekend', 'last_action_time_is_worktime', 'know_lens', 'full_lens', 'level', 'speed', 'max_load',\n",
    "                'pickup_delay_rate', 'delivery_delay_rate', 'pickup_delay_time_avg', 'delivery_delay_time_avg', 'delivery_delay_count', 'pickup_delay_count',\n",
    "                'last_action_type', 'last_weather', 'last_pick_lng', 'last_pick_lat', 'last_deliver_lng', 'last_deliver_lat', 'last_self_p_d_distance',\n",
    "                'last_load',\n",
    "               ] + weight_names + pass_names\n",
    "\n",
    "features_name = sorted( list( set(df_features_train_arugment.columns) - set(not_features)) )\n",
    "len_features_name = len(features_name)\n",
    "len_pair_features = 0\n",
    "\n",
    "pair_feature_name = list(map(lambda x : 'left_' + x, features_name) ) + list(map(lambda x : 'right_' + x, features_name) ) \n",
    "\n",
    "cat_feature_name = ['cur_action_type', 'cur_weather', 'delivery_estimate_time_exceed_120min', 'delivery_estimate_time_in_0min',\n",
    "                    'delivery_estimate_time_in_120min', 'delivery_estimate_time_in_15min', 'delivery_estimate_time_in_45min', \n",
    "                    'delivery_estimate_time_in_5min', 'same_tracking_id']\n",
    "\n",
    "cat_feature_name = list(set(cat_feature_name) - set(not_features))\n",
    "pair_cat_feature_name = list(map(lambda x : 'left_' + x, cat_feature_name) ) + list(map(lambda x : 'right_' + x, cat_feature_name) )\n",
    "\n",
    "logging.info('origin feature lens: %d' % len_features_name)\n",
    " \n",
    "\n",
    "def build_pair(se_1, se_2):\n",
    "    \n",
    "    pair_np = np.zeros((se_1.shape[0] * 2 + len_pair_features))\n",
    "    pair_np[ : se_1.shape[0] * 2] = np.concatenate([se_1.values, se_2.values])\n",
    "\n",
    "    return pair_np\n",
    "\n",
    "def apply_pairs_train(df):\n",
    "#     show_df(df)\n",
    "    df_feature = df[features_name]\n",
    "    right_se = df_feature.iloc[0]\n",
    "    n_sample = (df_feature.shape[0] - 1) * 2\n",
    "    n_feature = len_features_name * 2 + len_pair_features\n",
    "\n",
    "    sample_np = np.zeros((n_sample * 2, n_feature))\n",
    "    labels = np.zeros((n_sample * 2,))\n",
    "    p = 0\n",
    "    for i in range(1, df.shape[0]):\n",
    "        wrong_se = df_feature.iloc[i]\n",
    "        \n",
    "        sample_np[p] = build_pair(right_se, wrong_se)\n",
    "        labels[p] = 1\n",
    "        p += 1\n",
    "        \n",
    "        sample_np[p] = build_pair(wrong_se, right_se)\n",
    "        labels[p] = 0\n",
    "        p += 1\n",
    "        \n",
    "        \n",
    "    return sample_np[:p], labels[:p]\n",
    "\n",
    "def apply_pairs_train_data_arugment(df_arugment):\n",
    "    \n",
    "    gby_know_len = df_arugment.groupby('know_lens')\n",
    "    n_sample = 0\n",
    "    n_feature = len_features_name * 2 + len_pair_features\n",
    "\n",
    "    for know_len, df in gby_know_len:\n",
    "        n_sample += df.shape[0] - 1\n",
    "    n_pair = n_sample * (n_sample + 1)\n",
    "    \n",
    "    sample_np = np.zeros((n_pair, n_feature))\n",
    "    labels = np.zeros((n_pair,))\n",
    "    p = 0\n",
    "\n",
    "    for know_len, df in gby_know_len:\n",
    "        \n",
    "        df_feature = df[features_name]\n",
    "        right_se = df_feature.iloc[0]\n",
    "                \n",
    "        for i in range(1, df.shape[0]):\n",
    "            wrong_se = df_feature.iloc[i]\n",
    "\n",
    "            sample_np[p] = build_pair(right_se, wrong_se)\n",
    "            labels[p] = 1\n",
    "            p += 1\n",
    "\n",
    "            sample_np[p] = build_pair(wrong_se, right_se)\n",
    "            labels[p] = 0\n",
    "            p += 1\n",
    "            \n",
    "        \n",
    "    return sample_np[:p], labels[:p]\n",
    "\n",
    "\n",
    "def apply_pair_test(df):\n",
    "    df_feature = df[features_name]\n",
    "    n_sample = int(df_feature.shape[0] * (df_feature.shape[0] - 1))\n",
    "    n_feature = df_feature.shape[1] * 2 + len_pair_features\n",
    "    samples_np = np.zeros((n_sample, n_feature))\n",
    "    positions = np.zeros((n_sample, 2))\n",
    "    p = 0\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(i + 1, df.shape[0]):\n",
    "            samples_np[p] = build_pair(df_feature.iloc[i], df_feature.iloc[j])\n",
    "            positions[p] = np.array([df.iloc[i].target_position, df.iloc[j].target_position])\n",
    "            p += 1\n",
    "            \n",
    "            samples_np[p] = build_pair(df_feature.iloc[j], df_feature.iloc[i])\n",
    "            positions[p] = np.array([df.iloc[j].target_position, df.iloc[i].target_position])\n",
    "            p += 1\n",
    "\n",
    "    return samples_np, positions\n",
    "\n",
    "#about 4 min\n",
    "logging.info('start building se_pairs')\n",
    "# df_features_val = df_features_train.query('origin_i >= @VAL_POINT')\n",
    "# se_pairs_train = df_features_train.groupby('origin_i').apply(apply_pairs_train)\n",
    "# logging.info('finish building origin train')\n",
    "se_pairs_train_arugment = df_features_train_arugment.groupby('origin_i').apply(apply_pairs_train_data_arugment)\n",
    "logging.info('finish building train arugment')\n",
    "# se_pairs_val = df_features_val.groupby('origin_i').apply(apply_pair_test)\n",
    "se_pairs_testA = df_features_testA.groupby('origin_i').apply(apply_pair_test)\n",
    "se_pairs_testB = df_features_testB.groupby('origin_i').apply(apply_pair_test)\n",
    "logging.info('finish building se_pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "model_parms = {\n",
    "    'objective' : 'binary',\n",
    "    'learning_rate' : 0.01,\n",
    "    'boosting': 'gbdt',\n",
    "    'metric': 'auc' ,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 64,\n",
    "    'bagging_fraction':0.5,\n",
    "    'feature_fraction': 0.5,\n",
    "    'random_state' : np.random.randint(10e6)\n",
    "}\n",
    "\n",
    "def build_train_xy(se_pairs):\n",
    "    cnt_sample = 0\n",
    "    features_len = se_pairs.iloc[0][0].shape[1]\n",
    "    for (samples, labels) in se_pairs:\n",
    "        cnt_sample += samples.shape[0]\n",
    "    train_x, train_y = np.zeros((cnt_sample, features_len)), np.zeros((cnt_sample,))    \n",
    "    head, tail = 0, None\n",
    "    \n",
    "    for (samples, labels) in se_pairs:\n",
    "        tail = samples.shape[0] + head\n",
    "        train_x[head : tail] = samples\n",
    "        train_y[head : tail] = labels\n",
    "        head = tail\n",
    "        \n",
    "    return train_x, train_y\n",
    "\n",
    "def train_with_se_pair(se_pairs, learning_rate, epoch = 2000, val_mode = True):\n",
    "    model_parms['learning_rate'] = learning_rate\n",
    "    if val_mode:\n",
    "        se_pairs_train = se_pairs[se_pairs.index < VAL_POINT]\n",
    "        train_x, train_y = build_train_xy(se_pairs_train)\n",
    "        trn_data = lgb.Dataset(train_x, label=train_y, feature_name=pair_feature_name, categorical_feature=pair_cat_feature_name)\n",
    "        \n",
    "        se_pairs_val = se_pairs[se_pairs.index >= VAL_POINT]\n",
    "        val_x, val_y = build_train_xy(se_pairs_val)\n",
    "        val_data = lgb.Dataset(val_x, label=val_y, feature_name=pair_feature_name, categorical_feature=pair_cat_feature_name)\n",
    "        \n",
    "        valid_sets = [trn_data, val_data]\n",
    "        \n",
    "        logging.info('train shape:' + str(train_x.shape))\n",
    "        logging.info('val_x shape:' + str(val_x.shape))\n",
    "    else:\n",
    "        se_pairs_train = se_pairs\n",
    "        train_x, train_y = build_train_xy(se_pairs_train)\n",
    "        trn_data = lgb.Dataset(train_x, label=train_y, feature_name=pair_feature_name, categorical_feature=pair_cat_feature_name)\n",
    "        valid_sets = [trn_data, ]\n",
    "        logging.info('train shape:' + str(train_x.shape))\n",
    "\n",
    "\n",
    "    logging.info('start training')\n",
    "    model = lgb.train(model_parms, trn_data, epoch, valid_sets = valid_sets, verbose_eval=1000, early_stopping_rounds=2000)\n",
    "    logging.info('finish training')\n",
    "    \n",
    "    pre_train_y = model.predict(train_x)\n",
    "    train_acc = ((pre_train_y > 0.5) == train_y).sum() / len(train_y)\n",
    "    logging.info('train accury:%f' % train_acc)\n",
    "    \n",
    "    if val_mode:\n",
    "        pre_val_y = model.predict(val_x)\n",
    "        val_acc = ((pre_val_y > 0.5) == val_y).sum() / len(val_y)\n",
    "        logging.info('val accury:%f' % val_acc)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_choose_idx(df):\n",
    "    mp_cnt_win = {}\n",
    "    for pos_1, pos_2, score in df[['pos_1', 'pos_2', 'score']].values:\n",
    "        if(pos_1 not in mp_cnt_win):\n",
    "            mp_cnt_win[pos_1] = 0\n",
    "        mp_cnt_win[pos_1] += score\n",
    "\n",
    "    return max(mp_cnt_win, key=lambda x:mp_cnt_win[x])\n",
    "\n",
    "def test_with_se_pair(model, se_pairs):\n",
    "    cnt_sample = 0\n",
    "    features_len = se_pairs.iloc[0][0].shape[1]\n",
    "    for (samples, labels) in se_pairs:\n",
    "        cnt_sample += samples.shape[0]\n",
    "    test_x = np.zeros((cnt_sample, features_len))   \n",
    "    positions = np.zeros((cnt_sample, 2))\n",
    "    origin_idxs = np.zeros((cnt_sample, ))\n",
    "    head, tail = 0, None\n",
    "    \n",
    "    se_pairs_index = se_pairs.index\n",
    "    for i, (samples, position) in enumerate(se_pairs):\n",
    "        tail = samples.shape[0] + head\n",
    "        test_x[head : tail] = samples\n",
    "        positions[head : tail] = position\n",
    "        origin_idxs[head : tail] = se_pairs_index[i]\n",
    "        head = tail\n",
    "    \n",
    "    scores = model.predict(test_x)\n",
    "    df_idx_score = pd.DataFrame()\n",
    "    df_idx_score['origin_i'] = origin_idxs\n",
    "    df_idx_score['pos_1'] = positions[:, 0]\n",
    "    df_idx_score['pos_2'] = positions[:, 1]    \n",
    "    df_idx_score['score'] = scores  \n",
    "    se_choose_pos = df_idx_score.groupby('origin_i').apply(get_choose_idx)\n",
    "    return se_choose_pos\n",
    "\n",
    "def cal_rate(se_choose_pos, se_konw_lens):\n",
    "    mp_idx_choose_pos = se_choose_pos.to_dict()\n",
    "    cnt_right, cnt_right_without_rules = 0, 0\n",
    "    mp_idx_right_pos = se_konw_lens.to_dict()\n",
    "    wrong_idx_list = list()\n",
    "    for idx in mp_idx_right_pos:\n",
    "        if idx not in mp_idx_choose_pos:\n",
    "            cnt_right += 1\n",
    "        elif mp_idx_choose_pos[idx] == mp_idx_right_pos[idx]:\n",
    "            cnt_right += 1\n",
    "            cnt_right_without_rules += 1\n",
    "        else:\n",
    "            wrong_idx_list.append(idx)\n",
    "    return cnt_right / len(mp_idx_right_pos), cnt_right_without_rules / len(mp_idx_choose_pos), wrong_idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train & val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 08:49:07,207 - INFO - train shape:(191030, 236)\n",
      "2020-04-14 08:49:07,208 - INFO - val_x shape:(52532, 236)\n",
      "2020-04-14 08:49:07,209 - INFO - start training\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2000 rounds\n",
      "[1000]\ttraining's auc: 0.970221\tvalid_1's auc: 0.967629\n",
      "[2000]\ttraining's auc: 0.974942\tvalid_1's auc: 0.969574\n",
      "[3000]\ttraining's auc: 0.978096\tvalid_1's auc: 0.9701\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's auc: 0.978096\tvalid_1's auc: 0.9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 09:13:56,766 - INFO - finish training\n",
      "2020-04-14 09:14:04,608 - INFO - train accury:0.916139\n",
      "2020-04-14 09:14:06,843 - INFO - val accury:0.900860\n",
      "2020-04-14 09:14:06,939 - INFO - start val\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_train_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-940a8a0cd367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_se_choose_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_with_se_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mse_pairs_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate_without_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_idx_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_se_choose_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'know_lens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mVAL_POINT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finish val, rate:%f, %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate_without_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train_info' is not defined"
     ]
    }
   ],
   "source": [
    "# model = train_with_se_pair(se_pairs_train, 0.01, epoch = 3000)\n",
    "# logging.info('start val')\n",
    "# val_se_choose_pos = test_with_se_pair(model, se_pairs_val)\n",
    "# rate, rate_without_rule, wrong_idx_list = cal_rate(val_se_choose_pos, df_train_info['know_lens'].iloc[VAL_POINT:])\n",
    "# logging.info('finish val, rate:%f, %f' % (rate, rate_without_rule))\n",
    "\n",
    "# 0.863808, 0.838454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 09:23:57,867 - INFO - train shape:(940280, 236)\n",
      "2020-04-14 09:23:57,868 - INFO - val_x shape:(276062, 236)\n",
      "2020-04-14 09:23:57,869 - INFO - start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2000 rounds\n",
      "[1000]\ttraining's auc: 0.983368\tvalid_1's auc: 0.980019\n",
      "[2000]\ttraining's auc: 0.986535\tvalid_1's auc: 0.980476\n",
      "[3000]\ttraining's auc: 0.988913\tvalid_1's auc: 0.980578\n",
      "[4000]\ttraining's auc: 0.990818\tvalid_1's auc: 0.980604\n",
      "[5000]\ttraining's auc: 0.992431\tvalid_1's auc: 0.9806\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's auc: 0.992431\tvalid_1's auc: 0.9806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 10:16:11,260 - INFO - finish training\n",
      "2020-04-14 10:16:51,631 - INFO - train accury:0.952412\n",
      "2020-04-14 10:17:03,529 - INFO - val accury:0.919123\n",
      "2020-04-14 10:17:03,773 - INFO - start val\n",
      "2020-04-14 10:17:18,404 - INFO - finish val, rate:0.867061, 0.842312\n"
     ]
    }
   ],
   "source": [
    "# model = train_with_se_pair(se_pairs_train_arugment, 0.05, epoch = 5000)\n",
    "# logging.info('start val')\n",
    "# val_se_choose_pos = test_with_se_pair(model, se_pairs_val)\n",
    "# rate, rate_without_rule, wrong_idx_list = cal_rate(val_se_choose_pos, df_train_info['know_lens'].iloc[VAL_POINT:])\n",
    "# logging.info('finish val, rate:%f, %f' % (rate, rate_without_rule))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 10:18:45,166 - INFO - train shape:(1216342, 236)\n",
      "2020-04-14 10:18:45,166 - INFO - start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2000 rounds\n",
      "[1000]\ttraining's auc: 0.977916\n",
      "[2000]\ttraining's auc: 0.980279\n",
      "[3000]\ttraining's auc: 0.981408\n",
      "[4000]\ttraining's auc: 0.982241\n",
      "[5000]\ttraining's auc: 0.982941\n",
      "[6000]\ttraining's auc: 0.983563\n",
      "[7000]\ttraining's auc: 0.984128\n",
      "[8000]\ttraining's auc: 0.984656\n",
      "[9000]\ttraining's auc: 0.985155\n",
      "[10000]\ttraining's auc: 0.985627\n",
      "[11000]\ttraining's auc: 0.986074\n",
      "[12000]\ttraining's auc: 0.986504\n",
      "[13000]\ttraining's auc: 0.986905\n",
      "[14000]\ttraining's auc: 0.987297\n",
      "[15000]\ttraining's auc: 0.987678\n",
      "[16000]\ttraining's auc: 0.988034\n",
      "[17000]\ttraining's auc: 0.988382\n",
      "[18000]\ttraining's auc: 0.98872\n",
      "[19000]\ttraining's auc: 0.989054\n",
      "[20000]\ttraining's auc: 0.989375\n",
      "[21000]\ttraining's auc: 0.989679\n",
      "[22000]\ttraining's auc: 0.989981\n",
      "[23000]\ttraining's auc: 0.990272\n",
      "[24000]\ttraining's auc: 0.990552\n",
      "[25000]\ttraining's auc: 0.990827\n",
      "[26000]\ttraining's auc: 0.991088\n",
      "[27000]\ttraining's auc: 0.991351\n",
      "[28000]\ttraining's auc: 0.991604\n",
      "[29000]\ttraining's auc: 0.991848\n",
      "[30000]\ttraining's auc: 0.992089\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[30000]\ttraining's auc: 0.992089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 13:35:54,140 - INFO - finish training\n",
      "2020-04-14 14:04:14,641 - INFO - train accury:0.951143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0     1001\n",
       "0.0      980\n",
       "2.0      974\n",
       "3.0      706\n",
       "4.0      252\n",
       "5.0      138\n",
       "6.0       62\n",
       "7.0       41\n",
       "8.0       16\n",
       "9.0       13\n",
       "10.0       7\n",
       "12.0       1\n",
       "11.0       1\n",
       "14.0       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final = train_with_se_pair(se_pairs_train_arugment, 0.01, epoch = 30000, val_mode = False)\n",
    "# testB_se_choose_pos = test_with_se_pair(model_final, se_pairs_testB)\n",
    "# (testB_se_choose_pos - df_testB_info['know_lens']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testA_se_choose_pos = test_with_se_pair(model_final, se_pairs_testA)\n",
    "testA_choose_idxs = list(testA_se_choose_pos)\n",
    "\n",
    "pickle_path = '../user_data/makepair_gbdt/testA_choose_idxs.pickle'\n",
    "with open(pickle_path, 'wb') as f:\n",
    "    pickle.dump(testA_choose_idxs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testB_se_choose_pos = test_with_se_pair(model_final, se_pairs_testB)\n",
    "testB_choose_idxs = list(testB_se_choose_pos)\n",
    "\n",
    "pickle_path = '../user_data/makepair_gbdt/testB_choose_idxs.pickle'\n",
    "with open(pickle_path, 'wb') as f:\n",
    "    pickle.dump(testB_choose_idxs, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f98601a2940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.save_model('../user_data/makepair_gbdt/model_clf_pair.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(hyr)\n",
   "language": "python",
   "name": "hyr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
