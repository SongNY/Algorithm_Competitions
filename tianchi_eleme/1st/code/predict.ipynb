{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import logging\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "# logging.basicConfig(level=logging.INFO, filename='log_Model', format=LOG_FORMAT)\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "def show_df(df):\n",
    "    display(HTML(df.to_html()))\n",
    "\n",
    "VAL_POINT = 65623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.pos_encoder import *\n",
    "from tools.time_encoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('start prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data sort out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testB_dataset_path = '../data/eleme_round1_testB/'\n",
    "def read_a_day(dataset_path, read_date):\n",
    "    df_action = pd.read_csv('%saction/action_%s.txt' % (dataset_path, read_date.strftime('%Y%m%d')))\n",
    "    df_courier = pd.read_csv('%scourier/courier_%s.txt' % (dataset_path, read_date.strftime('%Y%m%d')))\n",
    "    df_distance = pd.read_csv('%sdistance/distance_%s.txt' % (dataset_path, read_date.strftime('%Y%m%d')))\n",
    "    df_order = pd.read_csv('%sorder/order_%s.txt' % (dataset_path, read_date.strftime('%Y%m%d')))\n",
    "    return df_action, df_courier, df_distance, df_order\n",
    "\n",
    "def read_days(start_date, end_date, data_dir):\n",
    "    cur_date = start_date\n",
    "    actions = []\n",
    "    couriers = []\n",
    "    distances = []\n",
    "    orders = []\n",
    "    while cur_date < end_date:\n",
    "        df_action, df_courier, df_distance, df_order = read_a_day(data_dir, cur_date)\n",
    "        df_action['date'] = cur_date\n",
    "        df_courier['date'] = cur_date\n",
    "        df_distance['date'] = cur_date\n",
    "        df_order['date'] = cur_date\n",
    "        \n",
    "        actions.append(df_action)\n",
    "        couriers.append(df_courier)\n",
    "        distances.append(df_distance)\n",
    "        orders.append(df_order)\n",
    "        cur_date += datetime.timedelta(days = 1)\n",
    "    \n",
    "    df_actions = pd.concat(actions, axis = 0, ignore_index = True)\n",
    "    df_couriers = pd.concat(couriers, axis = 0, ignore_index = True)    \n",
    "    df_distances = pd.concat(distances, axis = 0, ignore_index = True)    \n",
    "    df_orders = pd.concat(orders, axis = 0, ignore_index = True) \n",
    "    return df_actions, df_couriers, df_distances, df_orders\n",
    "\n",
    "df_actions_testB, df_couriers_testB, df_distances_testB, df_orders_testB = read_days(datetime.datetime(2020, 3, 1), datetime.datetime(2020, 3, 7), testB_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.74153423309326"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_map(df):\n",
    "    \"\"\"\n",
    "    将数据映射成字典，可通过\n",
    "        mp[date][courier_id][wave_index]\n",
    "    访问\n",
    "\n",
    "    \"\"\"\n",
    "    last_date, last_courier, last_wave = df.at[0, 'date'], df.at[0, 'courier_id'], df.at[0, 'wave_index']\n",
    "    last_i = 0\n",
    "    mp_date, mp_courier, mp_wave = {}, {}, {}\n",
    "    key_list = []\n",
    "    for i in range(1, df.shape[0]):\n",
    "        cur_wave = df.at[i, 'wave_index']\n",
    "        cur_courier = df.at[i, 'courier_id']\n",
    "        cur_date = df.at[i, 'date']\n",
    "\n",
    "        if last_wave != cur_wave or (last_wave == cur_wave and last_courier != cur_courier):\n",
    "            mp_wave[last_wave] = df.iloc[last_i : i]\n",
    "            last_i = i\n",
    "            key_list.append([last_date, last_courier, last_wave])\n",
    "            last_wave = cur_wave\n",
    "\n",
    "        if last_courier != cur_courier or (last_courier == cur_courier and last_date != cur_date):\n",
    "            mp_courier[last_courier] = mp_wave.copy()\n",
    "            mp_wave = {}\n",
    "            last_courier = cur_courier\n",
    "\n",
    "        if last_date != cur_date:\n",
    "            mp_date[last_date] = mp_courier.copy()\n",
    "            mp_courier = {}\n",
    "            last_date = cur_date\n",
    "    \n",
    "    mp_wave[last_wave] = df.iloc[last_i : ]\n",
    "    key_list.append([last_date, last_courier, last_wave])\n",
    "    mp_courier[last_courier] = mp_wave.copy()\n",
    "    mp_date[last_date] = mp_courier.copy()\n",
    "    mp_courier = {}\n",
    "    \n",
    "    return mp_date, key_list\n",
    "\n",
    "def get_map_distance_detail(mp_distance, key_list):\n",
    "    mp_distance_detail = {}\n",
    "    for (date, courier, wave_idx) in key_list:\n",
    "        if date not in mp_distance_detail:\n",
    "            mp_distance_detail[date] = {}\n",
    "        if courier not in mp_distance_detail[date]:\n",
    "            mp_distance_detail[date][courier] = {}\n",
    "        if wave_idx not in mp_distance_detail[date][courier]:\n",
    "            mp_distance_detail[date][courier][wave_idx] = {}\n",
    "        \n",
    "        df_a_distance = mp_distance[date][courier][wave_idx]\n",
    "        \n",
    "        gby_tracking = df_a_distance.groupby('tracking_id')\n",
    "        for tracking_id, df_track_id in gby_tracking:\n",
    "            mp_distance_detail[date][courier][wave_idx][tracking_id] = {}\n",
    "            gby_target_tracking = df_track_id.groupby('target_tracking_id')\n",
    "            for target_trackingid, df_target_tracking in gby_target_tracking:\n",
    "                mp_distance_detail[date][courier][wave_idx][tracking_id][target_trackingid] = df_target_tracking\n",
    "            \n",
    "    return mp_distance_detail\n",
    "\n",
    "start = time.time()\n",
    "mp_action_testB, action_key_list_testB = get_map(df_actions_testB)\n",
    "mp_distance_testB, distance_key_list_testB = get_map(df_distances_testB)\n",
    "mp_order_testB, order_key_list_testB = get_map(df_orders_testB)\n",
    "mp_distance_detail_testB = get_map_distance_detail(mp_distance_testB, action_key_list_testB)\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testB_dataset_mp = {\n",
    "    'key_list' : action_key_list_testB,\n",
    "    'mp_action' : mp_action_testB,\n",
    "    'mp_distance' : mp_distance_testB,\n",
    "    'mp_order' : mp_order_testB,\n",
    "    'mp_distance_detail' : mp_distance_detail_testB\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 18:31:47,764 - INFO - start\n",
      "2020-04-15 18:32:01,867 - INFO - end\n"
     ]
    }
   ],
   "source": [
    "logging.info('start')\n",
    "key_list_testB = testB_dataset_mp['key_list']\n",
    "testB_know_lens, testB_lens, testB_impossible_idxs = [], [], []\n",
    "for (date, courier, wave) in key_list_testB:\n",
    "    df_action = mp_action_testB[date][courier][wave]\n",
    "    testB_lens.append(df_action.shape[0])\n",
    "    df_konw = df_action.query('expect_time != 0')\n",
    "    df_unkonw = df_action.query('expect_time == 0')\n",
    "    testB_know_lens.append(df_konw.shape[0])\n",
    "    impossible_idx = []\n",
    "    konw_tracking_id = set(df_konw['tracking_id'])\n",
    "    for i, idx in enumerate(df_unkonw.index):\n",
    "        if df_unkonw.at[idx, 'tracking_id'] not in konw_tracking_id and df_unkonw.at[idx, 'action_type'] == 'DELIVERY':\n",
    "            impossible_idx.append(i)\n",
    "    testB_impossible_idxs.append(impossible_idx)\n",
    "\n",
    "df_testB_info = pd.DataFrame()\n",
    "df_testB_info['know_lens'] = testB_know_lens\n",
    "df_testB_info['lens'] = testB_lens\n",
    "df_testB_info['impossible_idxs'] = testB_impossible_idxs\n",
    "logging.info('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate_test_data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "courier_delay_features = ['pickup_delay_rate', 'delivery_delay_rate', 'pickup_delay_time_avg', 'delivery_delay_time_avg',\n",
    "                         'delivery_delay_count', 'pickup_delay_count']\n",
    "\n",
    "pickle_path = '../user_data/generate_train_test_courier_feature/mp_couriers_features_testB.pickle'\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    mp_couriers_features_testB = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mp_info_dict_testB = {\n",
    "    'action' : mp_action_testB,\n",
    "    'distance' : mp_distance_detail_testB,\n",
    "    'order' : mp_order_testB,\n",
    "    'couriers' : mp_couriers_features_testB\n",
    "}\n",
    "\n",
    "data_info_dict_testB = {\n",
    "    'konw_lens' : df_testB_info['know_lens'].values,\n",
    "    'full_lens' : df_testB_info['lens'].values,\n",
    "    'impossible_idxs' : df_testB_info['impossible_idxs'].values\n",
    "}\n",
    "\n",
    "mp_action_type = {'PICKUP' : 0, 'DELIVERY' : 1}\n",
    "mp_weather = {'正常天气' : 0, '轻微恶劣天气' : 1, '恶劣天气' : 2, '极恶劣天气' : 3}\n",
    "def get_static_action_feature_dict(prefix, se_a_action, df_a_order, df_a_distance):\n",
    "    feature_dict = {}\n",
    "    feature_dict[prefix + '_action_type'] = mp_action_type[se_a_action.action_type]\n",
    "    feature_dict[prefix + '_weather'] = mp_weather[df_a_order.loc[se_a_action.tracking_id]['weather_grade']]\n",
    "    se_lng_lat = df_a_order.loc[se_a_action.tracking_id][['pick_lng', 'pick_lat', 'deliver_lng', 'deliver_lat']]\n",
    "    se_lng_lat.index = prefix + '_' + se_lng_lat.index\n",
    "    feature_dict.update(se_lng_lat.to_dict())\n",
    "    \n",
    "    self_row = df_a_distance[se_a_action.tracking_id][se_a_action.tracking_id].query('source_type == \"PICKUP\" & target_type == \"DELIVERY\"')\n",
    "    feature_dict[prefix + '_self_p_d_distance'] = float(self_row['grid_distance'])\n",
    "    return feature_dict\n",
    "\n",
    "mp_row = {'ASSIGN' : 0, 'DELIVERY' : 1, 'PICKUP' : 2}\n",
    "def get_cross_action_feature_dict(last_action, cur_action, df_a_order, df_a_distance, speed):\n",
    "    features_dict = {}\n",
    "    #action\n",
    "    features_dict['same_tracking_id'] = (last_action.tracking_id == cur_action.tracking_id)\n",
    "    #order\n",
    "    features_dict['cur_pd_sub_last_time'] = df_a_order.loc[cur_action.tracking_id]['promise_deliver_time'] - last_action['expect_time']\n",
    "    features_dict['cur_ep_sub_last_time'] = df_a_order.loc[cur_action.tracking_id]['estimate_pick_time'] - last_action['expect_time']\n",
    "    features_dict['cur_assigned_sub_last_time'] = last_action['expect_time'] - df_a_order.loc[cur_action.tracking_id]['assigned_time']\n",
    "    features_dict['last_assigned_sub_last_time'] = last_action['expect_time'] - df_a_order.loc[last_action.tracking_id]['assigned_time']\n",
    "    \n",
    "    features_dict['cur_create_sub_last_time'] = last_action['expect_time'] - df_a_order.loc[cur_action.tracking_id]['create_time']\n",
    "    features_dict['last_create_sub_last_time'] = last_action['expect_time'] - df_a_order.loc[last_action.tracking_id]['create_time']\n",
    "    features_dict['cur_confirm_sub_last_time'] = last_action['expect_time'] - df_a_order.loc[cur_action.tracking_id]['confirm_time']\n",
    "    features_dict['last_confirm_sub_last_time'] = last_action['expect_time'] - df_a_order.loc[last_action.tracking_id]['confirm_time']\n",
    "\n",
    "    #distance\n",
    "    df_a_distance_relation = df_a_distance[last_action.tracking_id][cur_action.tracking_id]\n",
    "    df_a_distance_relation = df_a_distance_relation.sort_values(by = ['source_type', 'target_type'])    \n",
    "\n",
    "    if features_dict['same_tracking_id']:\n",
    "        idx = mp_row[last_action.action_type] * 2 + mp_row[cur_action.action_type]\n",
    "        features_dict['distance_a_a'] = 1.\n",
    "        features_dict['distance_a_d'] = df_a_distance_relation.iloc[0]['grid_distance'] \n",
    "        features_dict['distance_a_p'] = df_a_distance_relation.iloc[1]['grid_distance'] \n",
    "        features_dict['distance_d_a'] = df_a_distance_relation.iloc[2]['grid_distance'] \n",
    "        features_dict['distance_d_d'] = 1.\n",
    "        features_dict['distance_d_p'] = df_a_distance_relation.iloc[3]['grid_distance'] \n",
    "        features_dict['distance_p_a'] = df_a_distance_relation.iloc[4]['grid_distance'] \n",
    "        features_dict['distance_p_d'] = df_a_distance_relation.iloc[5]['grid_distance'] \n",
    "        features_dict['distance_p_p'] = 1.\n",
    "    else:\n",
    "        idx = mp_row[last_action.action_type] * 3 + mp_row[cur_action.action_type]\n",
    "        features_dict['distance_a_a'] = df_a_distance_relation.iloc[0]['grid_distance'] \n",
    "        features_dict['distance_a_d'] = df_a_distance_relation.iloc[1]['grid_distance'] \n",
    "        features_dict['distance_a_p'] = df_a_distance_relation.iloc[2]['grid_distance'] \n",
    "        features_dict['distance_d_a'] = df_a_distance_relation.iloc[3]['grid_distance'] \n",
    "        features_dict['distance_d_d'] = df_a_distance_relation.iloc[4]['grid_distance'] \n",
    "        features_dict['distance_d_p'] = df_a_distance_relation.iloc[5]['grid_distance'] \n",
    "        features_dict['distance_p_a'] = df_a_distance_relation.iloc[6]['grid_distance'] \n",
    "        features_dict['distance_p_d'] = df_a_distance_relation.iloc[7]['grid_distance'] \n",
    "        features_dict['distance_p_p'] = df_a_distance_relation.iloc[8]['grid_distance'] \n",
    "\n",
    "    a_distance_row = df_a_distance_relation.iloc[idx]\n",
    "    features_dict['grid_distance'] = a_distance_row['grid_distance']\n",
    "    \n",
    "    pos_dict = a_distance_row[['source_lng', 'source_lat', 'target_lng', 'target_lat']].to_dict()\n",
    "    pos_mutual_dict = mutual2pos(pos_dict['source_lat'], pos_dict['source_lng'], pos_dict['target_lat'], pos_dict['target_lng'], 'last_cur_position')\n",
    "    features_dict.update(pos_dict)\n",
    "    features_dict.update(pos_mutual_dict)\n",
    "    \n",
    "    #estimate time\n",
    "    features_dict['cur_action_estimate_time'] = features_dict['grid_distance'] / speed\n",
    "#     if cur_action.action_type == \"PICKUP\":\n",
    "    time_diff_pickup =  features_dict['cur_ep_sub_last_time'] - features_dict['cur_action_estimate_time']\n",
    "#     else:\n",
    "    time_diff_delivery = features_dict['cur_pd_sub_last_time'] - features_dict['cur_action_estimate_time']\n",
    "    \n",
    "    features_dict[\"estimate_time_diff_pickup\"] = time_diff_pickup\n",
    "    features_dict[\"pickup_estimate_time_in_0min\"] = time_diff_pickup < 0\n",
    "    features_dict[\"pickup_estimate_time_in_5min\"] = time_diff_pickup >= 0 and time_diff_pickup < 60 * 5\n",
    "    features_dict[\"pickup_estimate_time_in_15min\"] = time_diff_pickup >= 60 * 5 and time_diff_pickup < 60 * 15 \n",
    "    features_dict[\"pickup_estimate_time_in_45min\"] = time_diff_pickup >= 60 * 15 and time_diff_pickup < 60 * 45\n",
    "    features_dict[\"pickup_estimate_time_in_120min\"] = time_diff_pickup >= 60 * 45 and time_diff_pickup < 60 * 120\n",
    "    features_dict[\"pickup_estimate_time_exceed_120min\"] = time_diff_pickup >= 120 * 60\n",
    "    \n",
    "    features_dict[\"estimate_time_diff_delivery\"] = time_diff_delivery\n",
    "    features_dict[\"delivery_estimate_time_in_0min\"] = time_diff_delivery < 0\n",
    "    features_dict[\"delivery_estimate_time_in_5min\"] = time_diff_delivery >= 0 and time_diff_delivery < 60 * 5\n",
    "    features_dict[\"delivery_estimate_time_in_15min\"] = time_diff_delivery >= 60 * 5 and time_diff_delivery < 60 * 15 \n",
    "    features_dict[\"delivery_estimate_time_in_45min\"] = time_diff_delivery >= 60 * 15 and time_diff_delivery < 60 * 45\n",
    "    features_dict[\"delivery_estimate_time_in_120min\"] = time_diff_delivery >= 60 * 45 and time_diff_delivery < 60 * 120\n",
    "    features_dict[\"delivery_estimate_time_exceed_120min\"] = time_diff_delivery >= 120 * 60\n",
    "\n",
    "    \n",
    "    return features_dict\n",
    "\n",
    "def softmax_np(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def get_agg_action_feature_dict(tracking_ids, action_types, cur_action, last_time, \\\n",
    "                                  df_a_action, df_a_order, df_a_distance, prefix):\n",
    "    \n",
    "    cur_tracking_id = cur_action.tracking_id\n",
    "    cur_action_type = cur_action.action_type\n",
    "    \n",
    "    agg_feature_list = []\n",
    "    for i in range(len(tracking_ids)):\n",
    "        agg_feature_dict = {}\n",
    "        df_a_distance_relation = df_a_distance[cur_tracking_id][tracking_ids[i]]\n",
    "        next_action_type = action_types[i]\n",
    "        query_row = df_a_distance_relation.query('source_type == @cur_action_type & target_type == @next_action_type')\n",
    "        if query_row.shape[0] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            se_query_row = query_row.iloc[0]\n",
    "        pos_dict = se_query_row[['source_lng', 'source_lat', 'target_lng', 'target_lat']].to_dict()\n",
    "        pos_mutual_dict = mutual2pos(pos_dict['source_lat'], pos_dict['source_lng'], pos_dict['target_lat'], pos_dict['target_lng'], prefix)\n",
    "        agg_feature_dict.update(pos_mutual_dict)\n",
    "        agg_feature_dict[prefix + '_grid_distance'] = se_query_row['grid_distance']\n",
    "        agg_feature_dict[prefix + '_create_time_sub_last'] = last_time - df_a_order.loc[tracking_ids[i]].create_time \n",
    "        agg_feature_dict[prefix + '_confirm_time_sub_last'] = last_time - df_a_order.loc[tracking_ids[i]].confirm_time\n",
    "        agg_feature_dict[prefix + '_assigned_time_sub_last'] = last_time - df_a_order.loc[tracking_ids[i]].assigned_time\n",
    "        agg_feature_dict[prefix + '_promise_deliver_time_sub_last'] = df_a_order.loc[tracking_ids[i]].promise_deliver_time - last_time\n",
    "        agg_feature_dict[prefix + '_estimate_pick_time_sub_last'] = df_a_order.loc[tracking_ids[i]].estimate_pick_time - last_time\n",
    "\n",
    "        agg_feature_list.append(agg_feature_dict)\n",
    "    \n",
    "    df_agg_feature = pd.DataFrame(agg_feature_list)\n",
    "        \n",
    "    feature_dict = {}\n",
    "    se_mean = df_agg_feature.mean()\n",
    "    se_mean.index = se_mean.index + '_mean'\n",
    "    feature_dict.update(se_mean.to_dict())\n",
    "    \n",
    "    se_min = df_agg_feature.min()\n",
    "    se_min.index = se_min.index + '_min'\n",
    "    feature_dict.update(se_min.to_dict())\n",
    "\n",
    "    se_max = df_agg_feature.max()\n",
    "    se_max.index = se_max.index + '_max'\n",
    "    feature_dict.update(se_max.to_dict())\n",
    "    \n",
    "#     se_dist_weight = df_agg_feature.mul(softmax_np(1./df_agg_feature[prefix + '_haversine']), axis=0).sum()\n",
    "#     se_dist_weight.index = se_dist_weight.index + '_haversine_weight'\n",
    "#     feature_dict.update(se_dist_weight.to_dict())\n",
    "    \n",
    "#     se_time_weight = df_agg_feature.mul(softmax_np(1./df_agg_feature[prefix + '_promise_deliver_time_sub_last']), axis=0).sum()\n",
    "#     se_time_weight.index = se_time_weight.index + '_pd_time_weight'\n",
    "#     feature_dict.update(se_time_weight.to_dict())\n",
    "    \n",
    "    return feature_dict\n",
    "\n",
    "def a_feature_dict(i, j, df_a_action, start_action_expect_time, cur_action, last_action, know_len, full_len, \\\n",
    "                   se_a_couier, df_a_order, df_a_distance, last_load, unknow_tracking_ids, unknow_action_types,\\\n",
    "                  know_tracking_ids, know_action_types):\n",
    "    \n",
    "    cur_action = df_a_action.iloc[j]\n",
    "    features_dict = {}            \n",
    "\n",
    "    #generate features(can not be used)\n",
    "    features_dict['origin_i'] = i\n",
    "    features_dict['target_position'] = j\n",
    "    features_dict['start_action_expect_time'] = start_action_expect_time\n",
    "    features_dict['last_action_expect_time'] = last_action.expect_time\n",
    "    features_dict['cur_action_expect_time'] = cur_action.expect_time\n",
    "\n",
    "    #time feature\n",
    "    last_action_time_feature_dict = time_vector(last_action.expect_time, 'last_action_time')\n",
    "    features_dict.update(last_action_time_feature_dict)\n",
    "\n",
    "\n",
    "    #i fix features\n",
    "    features_dict['know_lens'] = know_len\n",
    "    features_dict['full_lens'] = full_len\n",
    "    features_dict.update(se_a_couier[['level', 'speed', 'max_load'] + courier_delay_features])\n",
    "\n",
    "    #last action features\n",
    "    last_action_static_feature = get_static_action_feature_dict('last', last_action, df_a_order, df_a_distance)\n",
    "    features_dict.update(last_action_static_feature)\n",
    "    features_dict['last_load'] = last_load\n",
    "\n",
    "    #cur action features\n",
    "    cur_action_static_feature = get_static_action_feature_dict('cur', cur_action, df_a_order, df_a_distance)\n",
    "    features_dict.update(cur_action_static_feature)\n",
    "    if cur_action.action_type == \"PICKUP\":\n",
    "        features_dict['cur_load'] = last_load + 1\n",
    "    else:\n",
    "        features_dict['cur_load'] = last_load - 1\n",
    "    features_dict['over_load'] = features_dict['cur_load'] > features_dict['max_load']\n",
    "\n",
    "    #cross feature\n",
    "    cross_features = get_cross_action_feature_dict(last_action, cur_action, df_a_order, df_a_distance, features_dict['speed'])\n",
    "    features_dict.update(cross_features)\n",
    "    \n",
    "    #agg feature\n",
    "    #future feature\n",
    "    future_features = get_agg_action_feature_dict(unknow_tracking_ids, unknow_action_types, cur_action, last_action.expect_time, \\\n",
    "                                                     df_a_action, df_a_order, df_a_distance, 'future_agg')\n",
    "#     pass feature\n",
    "    pass_features = get_agg_action_feature_dict(know_tracking_ids, know_action_types, cur_action, last_action.expect_time,\\\n",
    "                                                     df_a_action, df_a_order, df_a_distance, 'pass_agg')\n",
    "    \n",
    "    #all feature\n",
    "    all_features = get_agg_action_feature_dict(list(df_a_action.tracking_id), list(df_a_action.action_type), cur_action, last_action.expect_time,\\\n",
    "                                                     df_a_action, df_a_order, df_a_distance, 'all_agg')\n",
    "    \n",
    "    features_dict.update(future_features)\n",
    "    features_dict.update(pass_features)\n",
    "    features_dict.update(all_features)\n",
    "  \n",
    "    return features_dict\n",
    "\n",
    "\n",
    "def generate_gbdt_df(key_list, mp_info_dict, data_info_dict):\n",
    "    mp_action, mp_distance, mp_order, mp_couriers = mp_info_dict['action'],  mp_info_dict['distance'],  mp_info_dict['order'],  mp_info_dict['couriers']\n",
    "    know_lens, full_lens, impossible_idxs = data_info_dict['konw_lens'], data_info_dict['full_lens'], data_info_dict['impossible_idxs']\n",
    "    features_dict_list = []\n",
    "    for i in range(len(key_list)):\n",
    "        if (i+1) % 1000 == 0:\n",
    "            logging.info('%d' % i)\n",
    "        \n",
    "        date, courier, wave_idx = key_list[i]\n",
    "        df_a_action = mp_action[date][courier][wave_idx]\n",
    "        df_a_distance = mp_distance[date][courier][wave_idx]\n",
    "        df_a_order = mp_order[date][courier][wave_idx]\n",
    "        df_a_order.index = df_a_order.tracking_id\n",
    "        se_a_couier = mp_couriers[courier][date]        \n",
    "        impossible_idx_set = set(impossible_idxs[i])\n",
    "        \n",
    "        start_action_expect_time = df_a_action.iloc[0].expect_time\n",
    "        last_action = df_a_action.iloc[know_lens[i] - 1]\n",
    "        pickup_num = df_a_action.query('action_type == \"PICKUP\"').shape[0] \n",
    "        delivery_num = know_lens[i] - pickup_num\n",
    "        last_load = pickup_num - delivery_num \n",
    "        \n",
    "        df_unknow_action = df_a_action.iloc[know_lens[i] : full_lens[i]]\n",
    "        unknow_tracking_ids, unknow_action_types = list(df_unknow_action.tracking_id), list(df_unknow_action.action_type)\n",
    "        \n",
    "        df_know_action = df_a_action.iloc[: know_lens[i]]\n",
    "        know_tracking_ids, know_action_types = list(df_know_action.tracking_id), list(df_know_action.action_type)\n",
    "\n",
    "        for j in range(know_lens[i], full_lens[i]):\n",
    "            if j - know_lens[i] in impossible_idx_set:\n",
    "                continue\n",
    "                \n",
    "            cur_action = df_a_action.iloc[j]\n",
    "            know_len, full_len = know_lens[i], full_lens[i]\n",
    "            features_dict = a_feature_dict(i, j, df_a_action, start_action_expect_time, cur_action, last_action, know_len, full_len,\\\n",
    "                   se_a_couier, df_a_order, df_a_distance, last_load, unknow_tracking_ids, unknow_action_types, know_tracking_ids, know_action_types)\n",
    "            features_dict_list.append(features_dict)\n",
    "    \n",
    "    df_features = pd.DataFrame(features_dict_list)\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/pandas/core/series.py:1155: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n",
      "2020-04-15 18:37:33,214 - INFO - 999\n",
      "2020-04-15 18:43:13,355 - INFO - 1999\n",
      "2020-04-15 18:49:07,854 - INFO - 2999\n",
      "2020-04-15 18:55:30,657 - INFO - 3999\n"
     ]
    }
   ],
   "source": [
    "df_features_testB = generate_gbdt_df(key_list_testB, mp_info_dict_testB, data_info_dict_testB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# makepair_gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 18:56:43,181 - INFO - origin feature lens: 118\n",
      "2020-04-15 18:56:43,183 - INFO - start building se_pairs\n",
      "2020-04-15 18:57:26,946 - INFO - finish building se_pairs\n"
     ]
    }
   ],
   "source": [
    "weight_names = []\n",
    "pass_names = []\n",
    "all_agg_names = []\n",
    "for name in df_features_testB.columns:\n",
    "    if '_weight' in name:\n",
    "        weight_names.append(name)\n",
    "    if 'pass_agg' in name:\n",
    "        pass_names.append(name)\n",
    "    if 'all_agg' in name:\n",
    "        all_agg_names.append(name)\n",
    "\n",
    "        \n",
    "not_features = ['origin_i', 'target_position', 'start_action_expect_time', 'last_action_expect_time', 'cur_action_expect_time',\n",
    "                'last_action_time_hour', 'last_action_time_minute', 'last_action_time_second', 'last_action_time_weekday', \n",
    "                'last_action_time_is_weekend', 'last_action_time_is_worktime', 'know_lens', 'full_lens', 'level', 'speed', 'max_load',\n",
    "                'pickup_delay_rate', 'delivery_delay_rate', 'pickup_delay_time_avg', 'delivery_delay_time_avg', 'delivery_delay_count', 'pickup_delay_count',\n",
    "                'last_action_type', 'last_weather', 'last_pick_lng', 'last_pick_lat', 'last_deliver_lng', 'last_deliver_lat', 'last_self_p_d_distance',\n",
    "                'last_load',\n",
    "               ] + weight_names + pass_names\n",
    "\n",
    "features_name = sorted( list( set(df_features_testB.columns) - set(not_features)) )\n",
    "len_features_name = len(features_name)\n",
    "len_pair_features = 0\n",
    "\n",
    "pair_feature_name = list(map(lambda x : 'left_' + x, features_name) ) + list(map(lambda x : 'right_' + x, features_name) ) \n",
    "\n",
    "cat_feature_name = ['cur_action_type', 'cur_weather', 'delivery_estimate_time_exceed_120min', 'delivery_estimate_time_in_0min',\n",
    "                    'delivery_estimate_time_in_120min', 'delivery_estimate_time_in_15min', 'delivery_estimate_time_in_45min', \n",
    "                    'delivery_estimate_time_in_5min', 'same_tracking_id']\n",
    "\n",
    "cat_feature_name = list(set(cat_feature_name) - set(not_features))\n",
    "pair_cat_feature_name = list(map(lambda x : 'left_' + x, cat_feature_name) ) + list(map(lambda x : 'right_' + x, cat_feature_name) )\n",
    "\n",
    "logging.info('origin feature lens: %d' % len_features_name)\n",
    " \n",
    "\n",
    "def build_pair(se_1, se_2):\n",
    "    \n",
    "    pair_np = np.zeros((se_1.shape[0] * 2 + len_pair_features))\n",
    "    pair_np[ : se_1.shape[0] * 2] = np.concatenate([se_1.values, se_2.values])\n",
    "\n",
    "    return pair_np\n",
    "\n",
    "def apply_pairs_train(df):\n",
    "#     show_df(df)\n",
    "    df_feature = df[features_name]\n",
    "    right_se = df_feature.iloc[0]\n",
    "    n_sample = (df_feature.shape[0] - 1) * 2\n",
    "    n_feature = len_features_name * 2 + len_pair_features\n",
    "\n",
    "    sample_np = np.zeros((n_sample * 2, n_feature))\n",
    "    labels = np.zeros((n_sample * 2,))\n",
    "    p = 0\n",
    "    for i in range(1, df.shape[0]):\n",
    "        wrong_se = df_feature.iloc[i]\n",
    "        \n",
    "        sample_np[p] = build_pair(right_se, wrong_se)\n",
    "        labels[p] = 1\n",
    "        p += 1\n",
    "        \n",
    "        sample_np[p] = build_pair(wrong_se, right_se)\n",
    "        labels[p] = 0\n",
    "        p += 1\n",
    "        \n",
    "        \n",
    "    return sample_np[:p], labels[:p]\n",
    "\n",
    "def apply_pairs_train_data_arugment(df_arugment):\n",
    "    \n",
    "    gby_know_len = df_arugment.groupby('know_lens')\n",
    "    n_sample = 0\n",
    "    n_feature = len_features_name * 2 + len_pair_features\n",
    "\n",
    "    for know_len, df in gby_know_len:\n",
    "        n_sample += df.shape[0] - 1\n",
    "    n_pair = n_sample * (n_sample + 1)\n",
    "    \n",
    "    sample_np = np.zeros((n_pair, n_feature))\n",
    "    labels = np.zeros((n_pair,))\n",
    "    p = 0\n",
    "\n",
    "    for know_len, df in gby_know_len:\n",
    "        \n",
    "        df_feature = df[features_name]\n",
    "        right_se = df_feature.iloc[0]\n",
    "                \n",
    "        for i in range(1, df.shape[0]):\n",
    "            wrong_se = df_feature.iloc[i]\n",
    "\n",
    "            sample_np[p] = build_pair(right_se, wrong_se)\n",
    "            labels[p] = 1\n",
    "            p += 1\n",
    "\n",
    "            sample_np[p] = build_pair(wrong_se, right_se)\n",
    "            labels[p] = 0\n",
    "            p += 1\n",
    "            \n",
    "        \n",
    "    return sample_np[:p], labels[:p]\n",
    "\n",
    "\n",
    "def apply_pair_test(df):\n",
    "    df_feature = df[features_name]\n",
    "    n_sample = int(df_feature.shape[0] * (df_feature.shape[0] - 1))\n",
    "    n_feature = df_feature.shape[1] * 2 + len_pair_features\n",
    "    samples_np = np.zeros((n_sample, n_feature))\n",
    "    positions = np.zeros((n_sample, 2))\n",
    "    p = 0\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(i + 1, df.shape[0]):\n",
    "            samples_np[p] = build_pair(df_feature.iloc[i], df_feature.iloc[j])\n",
    "            positions[p] = np.array([df.iloc[i].target_position, df.iloc[j].target_position])\n",
    "            p += 1\n",
    "            \n",
    "            samples_np[p] = build_pair(df_feature.iloc[j], df_feature.iloc[i])\n",
    "            positions[p] = np.array([df.iloc[j].target_position, df.iloc[i].target_position])\n",
    "            p += 1\n",
    "\n",
    "    return samples_np, positions\n",
    "\n",
    "#about 4 min\n",
    "logging.info('start building se_pairs')\n",
    "se_pairs_testB = df_features_testB.groupby('origin_i').apply(apply_pair_test)\n",
    "logging.info('finish building se_pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_choose_idx(df):\n",
    "    mp_cnt_win = {}\n",
    "    for pos_1, pos_2, score in df[['pos_1', 'pos_2', 'score']].values:\n",
    "        if(pos_1 not in mp_cnt_win):\n",
    "            mp_cnt_win[pos_1] = 0\n",
    "        mp_cnt_win[pos_1] += score\n",
    "\n",
    "    return max(mp_cnt_win, key=lambda x:mp_cnt_win[x])\n",
    "\n",
    "def test_with_se_pair(model, se_pairs):\n",
    "    cnt_sample = 0\n",
    "    features_len = se_pairs.iloc[0][0].shape[1]\n",
    "    for (samples, labels) in se_pairs:\n",
    "        cnt_sample += samples.shape[0]\n",
    "    test_x = np.zeros((cnt_sample, features_len))   \n",
    "    positions = np.zeros((cnt_sample, 2))\n",
    "    origin_idxs = np.zeros((cnt_sample, ))\n",
    "    head, tail = 0, None\n",
    "    \n",
    "    se_pairs_index = se_pairs.index\n",
    "    for i, (samples, position) in enumerate(se_pairs):\n",
    "        tail = samples.shape[0] + head\n",
    "        test_x[head : tail] = samples\n",
    "        positions[head : tail] = position\n",
    "        origin_idxs[head : tail] = se_pairs_index[i]\n",
    "        head = tail\n",
    "    \n",
    "    scores = model.predict(test_x)\n",
    "    df_idx_score = pd.DataFrame()\n",
    "    df_idx_score['origin_i'] = origin_idxs\n",
    "    df_idx_score['pos_1'] = positions[:, 0]\n",
    "    df_idx_score['pos_2'] = positions[:, 1]    \n",
    "    df_idx_score['score'] = scores  \n",
    "    se_choose_pos = df_idx_score.groupby('origin_i').apply(get_choose_idx)\n",
    "    return se_choose_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model_final = lgb.Booster(model_file='../user_data/makepair_gbdt/model_clf_pair.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testB_se_choose_pos = test_with_se_pair(model_final, se_pairs_testB)\n",
    "testB_choose_idxs = list(testB_se_choose_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regress_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_testB['choose_position'] = df_features_testB['origin_i'].map(lambda x : testB_choose_idxs[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = '../user_data/regress_task/reg_features_name.pickle'\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    reg_features_name = pickle.load(f)\n",
    "# reg_features_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_features = ['origin_i', 'target_position', 'cur_action_expect_time', 'choose_position']\n",
    "# reg_features_name = list( set(df_features_testB.columns) - set(not_features))\n",
    "\n",
    "def apply_regress_sample(df):\n",
    "    df_choose_rows = df.query('target_position == choose_position')\n",
    "    df_choose_rows['label'] = df_choose_rows['cur_action_expect_time'] - df_choose_rows['last_action_expect_time']\n",
    "    return df_choose_rows[reg_features_name + ['label']]\n",
    "df_regress_testB = df_features_testB.groupby('origin_i').apply(apply_regress_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_features = ['origin_i', 'target_position', 'cur_action_expect_time', 'choose_position']\n",
    "# reg_features_name = list( set(df_features_testB.columns) - set(not_features))\n",
    "\n",
    "def apply_regress_sample(df):\n",
    "    df_choose_rows = df.query('target_position == choose_position')\n",
    "    df_choose_rows['label'] = df_choose_rows['cur_action_expect_time'] - df_choose_rows['last_action_expect_time']\n",
    "    return df_choose_rows[reg_features_name + ['label']]\n",
    "\n",
    "def test_process_reg(model, df_regress_testB):\n",
    "    pre = model.predict(df_regress_testB[reg_features_name])\n",
    "    return pre + df_regress_testB['last_action_expect_time'] \n",
    "\n",
    "def get_reg_result(testB_choose_idxs, df_features_testB, model):\n",
    "    df_features_testB['choose_position'] = df_features_testB['origin_i'].map(lambda x : testB_choose_idxs[x])\n",
    "    df_regress_testB = df_features_testB.groupby('origin_i').apply(apply_regress_sample)\n",
    "    se_testB_expect_times = test_process_reg(model, df_regress_testB)\n",
    "    return se_testB_expect_times\n",
    "\n",
    "model_reg = lgb.Booster(model_file='../user_data/regress_task/model_reg.txt')\n",
    "se_testB_expect_times = get_reg_result(testB_choose_idxs, df_features_testB, model_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_str = str(datetime.datetime.now()).replace(':', '_')\n",
    "test_expect_times_list = list(se_testB_expect_times)\n",
    "\n",
    "submit_dir = '../action_predict/'\n",
    "if os.path.exists(submit_dir) == False:\n",
    "    os.mkdir(submit_dir)\n",
    "cur_date_str = None\n",
    "for i, (date, courier, wave_idx) in enumerate(key_list_testB):\n",
    "    df_a_action = mp_action_testB[date][courier][wave_idx]\n",
    "    choose_idx = int(testB_choose_idxs[i])\n",
    "    choose_row = df_a_action.iloc[choose_idx]\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "\n",
    "    if cur_date_str != date_str:\n",
    "        if cur_date_str != None:\n",
    "            f.close()\n",
    "        cur_date_str = date_str\n",
    "        f = open(submit_dir + 'action_' + cur_date_str + '.txt', 'w+')\n",
    "        f.write('courier_id,wave_index,tracking_id,courier_wave_start_lng,courier_wave_start_lat,action_type,expect_time\\n')\n",
    "    a_line = '%d,%d,%d,%.6f,%.6f,%s,%f\\n'% (choose_row['courier_id'], choose_row['wave_index'], choose_row['tracking_id'],\\\n",
    "                                            choose_row['courier_wave_start_lng'], choose_row['courier_wave_start_lat'], \\\n",
    "                                            choose_row['action_type'], test_expect_times_list[i],)\n",
    "    f.write(a_line)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('finish prediction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(hyr)\n",
   "language": "python",
   "name": "hyr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
