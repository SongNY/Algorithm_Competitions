{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.utils import shuffle\n",
    "import gc\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history_action = pd.read_pickle('./temp/action_history_f.plk')\n",
    "df_feature = pd.read_pickle('./temp/base_feature_f.plk')\n",
    "df_courier = pd.read_pickle('./temp/courier.plk')\n",
    "df_order = pd.read_pickle('./temp/order.plk')\n",
    "df_distance = pd.read_pickle('./temp/distance.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_history_action.groupby(['group'])['expect_time'].apply(\n",
    "    lambda x: x.values.tolist()[-1]).reset_index()\n",
    "df_temp.columns = ['group', 'current_time']\n",
    "df_feature = df_feature.merge(df_temp, how='left')\n",
    "\n",
    "df_temp = df_history_action.groupby(['group'])['tracking_id'].apply(\n",
    "    lambda x: x.values.tolist()[-1]).reset_index()\n",
    "df_temp.columns = ['group', 'last_tracking_id']\n",
    "df_feature = df_feature.merge(df_temp, how='left')\n",
    "\n",
    "df_temp = df_history_action.groupby(['group'])['action_type'].apply(\n",
    "    lambda x: x.values.tolist()[-1]).reset_index()\n",
    "df_temp.columns = ['group', 'last_action_type']\n",
    "df_feature = df_feature.merge(df_temp, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distance = df_distance.rename(columns={'tracking_id': 'last_tracking_id',\n",
    "                                          'source_type': 'last_action_type', \n",
    "                                          'target_tracking_id': 'tracking_id',\n",
    "                                          'target_type': 'action_type'})\n",
    "df_feature = df_feature.merge(df_distance.drop(\n",
    "    ['courier_id', 'wave_index', 'date'], axis=1), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = df_feature.merge(\n",
    "    df_order[['tracking_id', 'weather_grade', 'aoi_id', 'shop_id', 'promise_deliver_time',\n",
    "              'estimate_pick_time']], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = df_feature.merge(df_courier, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum=df_feature.groupby(['group']).size().reset_index()\n",
    "df_sum.columns = ['group','unfinished_num_sum']\n",
    "df_feature = df_feature.merge(df_sum, how='left')\n",
    "\n",
    "df_order['group']=df_order['date'].astype(\n",
    "    'str') + df_order['courier_id'].astype('str') + df_order['wave_index'].astype('str')\n",
    "df_sum=df_order.groupby(['group']).size().reset_index()\n",
    "df_sum.columns = ['group','all_order_num']\n",
    "df_feature = df_feature.merge(df_sum, how='left')\n",
    "df_feature['finish_freq']=df_feature['unfinished_num_sum']/df_feature['all_order_num']/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature['delta_lng']=df_feature['source_lng']-df_feature['target_lng']\n",
    "df_feature['delta_lat']=df_feature['source_lat']-df_feature['target_lat']\n",
    "df_feature['delta_abs_lng']=abs(df_feature['source_lng']-df_feature['target_lng'])\n",
    "df_feature['delta_abs_lat']=abs(df_feature['source_lat']-df_feature['target_lat'])\n",
    "df_feature['delta_dis']=(df_feature['delta_lng']**2+df_feature['delta_lat']**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature['lng_max']=0\n",
    "id_index=df_feature.groupby('group')['delta_lng'].idxmax()\n",
    "df_feature.loc[id_index,'lng_max']=1\n",
    "\n",
    "df_feature['lng_min']=0\n",
    "id_index=df_feature.groupby('group')['delta_lng'].idxmin()\n",
    "df_feature.loc[id_index,'lng_min']=1\n",
    "\n",
    "df_feature['lat_max']=0\n",
    "id_index=df_feature.groupby('group')['delta_lat'].idxmax()\n",
    "df_feature.loc[id_index,'lat_max']=1\n",
    "\n",
    "df_feature['lat_min']=0\n",
    "id_index=df_feature.groupby('group')['delta_lat'].idxmin()\n",
    "df_feature.loc[id_index,'lat_min']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature['latest_grid']=0\n",
    "id_index=df_feature.groupby('group')['grid_distance'].idxmin()\n",
    "df_feature.loc[id_index,'latest_grid']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature['delta_pick_time']=df_feature['estimate_pick_time']-df_feature['current_time']\n",
    "df_feature['delta_deliver_time']=df_feature['promise_deliver_time']-df_feature['current_time']\n",
    "df_feature['current_hour']=pd.to_datetime(df_feature['current_time'].values, utc=True, unit='s').tz_convert(\n",
    "            \"Asia/Shanghai\").hour\n",
    "df_feature['current_hour_bin']='other'\n",
    "df_feature.loc[df_feature['current_hour'].isin([11,12,13]),'current_hour_bin']='lunch'\n",
    "df_feature.loc[df_feature['current_hour'].isin([17,18,19]),'current_hour_bin']='dinner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature['latest_deliver']=0\n",
    "id_index=df_feature.groupby('group')['delta_deliver_time'].idxmin()\n",
    "df_feature.loc[id_index,'latest_deliver']=1\n",
    "del id_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.to_pickle('./temp/part1_feature_f.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "一些基本特征: 波次,行动种类,待送单数,总订单数,前一行动种类,天气,\n",
    "距离相关特征: #波次开始位置,当前位置,目标取货位置,目标送达位置; \n",
    "            相对位置,相对距离,高德距离;\n",
    "距离相关特征: 当前时间,取单时间,承诺送达时间,当前小时;\n",
    "            取单时间-当前时间,承诺送达时间-当前时间;\n",
    "骑手信息特征: 骑手id,level,speed,max_load\n",
    "\n",
    "y:expect_time target\n",
    "\n",
    "无用特征: #骑士id,#目标订单id,#前一订单id,aoi_id,shop_id,date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_base_name=['wave_index','action_type','unfinished_num_sum','last_action_type','weather_grade']\n",
    "df_feature_distance_name=['delta_lng','delta_lat','delta_abs_lng','delta_abs_lat','delta_dis','grid_distance',\n",
    "                         'latest_grid','lat_max','lat_min','lng_min','lng_max']\n",
    "df_feature_time_name=['delta_pick_time','delta_deliver_time','latest_deliver','current_hour','current_hour_bin']\n",
    "df_feature_courier_name=['level','speed','max_load']\n",
    "df_feature_name=df_feature_base_name+df_feature_distance_name+df_feature_time_name+df_feature_courier_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_type\n",
      "last_action_type\n",
      "weather_grade\n",
      "aoi_id\n",
      "shop_id\n",
      "current_hour_bin\n"
     ]
    }
   ],
   "source": [
    "for f in df_feature.select_dtypes('object'):\n",
    "    if f not in ['date', 'type','group']:\n",
    "        print(f)\n",
    "        lbl = LabelEncoder()\n",
    "        df_feature[f] = lbl.fit_transform(df_feature[f].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testA = df_feature[df_feature['type'] == 'testA'].copy()\n",
    "df_test = df_feature[df_feature['type'] == 'testB'].copy()\n",
    "df_train = df_feature[df_feature['type'] == 'train'].copy()\n",
    "df_train = shuffle(df_train, random_state=513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycol = 'target'\n",
    "feature_names = df_feature_name\n",
    "params = {\n",
    "    'num_leaves':31,\n",
    "    'n_estimators': 10000,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'is_unbalance':'true',\n",
    "    'metrics':'group_acc',\n",
    "    'early_stopping_rounds': 50,\n",
    "    'num_threads':20,\n",
    "    'seed':513\n",
    "}\n",
    "\n",
    "oof = []\n",
    "prediction = df_test[['id', 'group']]\n",
    "prediction['target'] = 0\n",
    "df_importance_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_group_func(group):\n",
    "    target_list = group['label'].values.tolist()\n",
    "    pred_list = group['pred'].values.tolist()\n",
    "    max_index = pred_list.index(max(pred_list))\n",
    "    if target_list[max_index] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def group_acc(preds,dtrain):\n",
    "    label=dtrain.get_label()\n",
    "    pred_list=pd.DataFrame({'group':val_group,\n",
    "                            'pred':preds,\n",
    "                            'label':label})\n",
    "    df_temp =pred_list.groupby(['group']).apply(wave_group_func).reset_index()\n",
    "    df_temp.columns = ['group', 'label']\n",
    "    acc = df_temp[df_temp['label'] == 1].shape[0] / df_temp.shape[0]\n",
    "    return 'group_acc',float(acc),True\n",
    "\n",
    "kfold = GroupKFold(n_splits=5)\n",
    "kfold_in = GroupKFold(n_splits=5)\n",
    "for fold_id, (trn_idx, val_idx) in enumerate(kfold.split(df_train[feature_names], df_train[ycol], df_train['group'])):\n",
    "    X_train = df_train.iloc[trn_idx][feature_names+['group']]\n",
    "    Y_train = df_train.iloc[trn_idx][ycol]\n",
    "    X_val = df_train.iloc[val_idx][feature_names+['group']]\n",
    "    Y_val = df_train.iloc[val_idx][ycol]\n",
    "    groupp=df_train.iloc[val_idx]['group'].values\n",
    "    pred_val=np.zeros(X_val.shape[0])\n",
    "if 1:\n",
    "    for fold_in_id, (train_in_idx, val_in_idx) in enumerate(kfold_in.split(X_train, Y_train, X_train['group'])):\n",
    "        val_group=X_train['group'].iloc[val_in_idx]\n",
    "        train_set = lgb.Dataset(X_train.drop(columns='group').iloc[train_in_idx], Y_train.iloc[train_in_idx])\n",
    "        val_set = lgb.Dataset(X_train.drop(columns='group').iloc[val_in_idx], Y_train.iloc[val_in_idx])\n",
    "        model = lgb.train(params, train_set,valid_sets=val_set,\n",
    "                          categorical_feature=['weather_grade','current_hour_bin'],\n",
    "                          feval=group_acc,verbose_eval=10)\n",
    "        pred_test = model.predict(X_val.drop(columns='group'))\n",
    "        \n",
    "        df_importance = pd.DataFrame({\n",
    "        'column': model.feature_name(),\n",
    "        'importance': model.feature_importance('gain')})\n",
    "        df_importance_list.append(df_importance)\n",
    "        pred_val += pred_test / 5\n",
    "        print('========================================')\n",
    "    pred_df = pd.DataFrame({'group':groupp,\n",
    "                                'pred':pred_val,\n",
    "                                'label':Y_val.values})\n",
    "    df_temp = pred_df.groupby(['group']).apply(wave_group_func).reset_index()\n",
    "    df_temp.columns = ['group', 'label']\n",
    "    acc = df_temp[df_temp['label'] == 1].shape[0] / df_temp.shape[0]\n",
    "    print('acc:', acc)\n",
    "    print('=======================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves':31,\n",
    "    'n_estimators': 200,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'is_unbalance':'true',\n",
    "    'objective': 'binary',\n",
    "    'num_threads':20\n",
    "}\n",
    "train_set = lgb.Dataset(df_train[df_feature_name], df_train['target'],free_raw_data=False)\n",
    "model_final = lgb.train(params,train_set,\n",
    "                       categorical_feature=['weather_grade','current_hour_bin'],)\n",
    "pred=model_final.predict(df_test[df_feature_name])\n",
    "df_test['pred']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_train=copy.deepcopy(df_train[df_train['target']==1])\n",
    "time_train['detla_time']=time_train['expect_time']-time_train['current_time']\n",
    "param = {\n",
    "    'num_leaves':31,\n",
    "    'n_estimators': 10000,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'mae',\n",
    "    'metrics':'mae',\n",
    "    'early_stopping_rounds': 50,\n",
    "    'num_threads':20\n",
    "}\n",
    "train_time_set = lgb.Dataset(time_train[df_feature_name],time_train['detla_time'])\n",
    "model_time_cv=lgb.cv(param,train_time_set,nfold=5,metrics='mae',\n",
    "                     categorical_feature=['current_hour_bin','weather_grade'])\n",
    "n_east=len(model_time_cv['l1-mean'])\n",
    "\n",
    "param = {\n",
    "    'num_leaves':31,\n",
    "    'n_estimators': n_east,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'mae',\n",
    "    'num_threads':20\n",
    "}\n",
    "model_time=lgb.train(param,train_time_set,\n",
    "                     categorical_feature=['current_hour_bin','weather_grade'])\n",
    "pred_time=model_time.predict(df_test[df_feature_name])\n",
    "df_test['expect_time']=df_test['current_time']+pred_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred=model_final.predict(df_test[df_feature_name])\n",
    "# df_test['pred']=pred\n",
    "same_track_id=df_test.groupby('tracking_id').size()[df_test.groupby('tracking_id').size()==2].reset_index()['tracking_id'].values.tolist()\n",
    "df_test_afterchoice=df_test[~((df_test['tracking_id'].isin(same_track_id)) & (df_test['action_type']==0))]\n",
    "maxid=df_test_afterchoice.groupby('group')['pred'].idxmax()\n",
    "df_sub=copy.deepcopy(df_test_afterchoice.loc[maxid])\n",
    "df_sub.loc[df_sub['action_type']==0,'action_type']='DELIVERY'\n",
    "df_sub.loc[df_sub['action_type']==1,'action_type']='PICKUP'\n",
    "prediction=df_sub[['courier_id','wave_index','tracking_id','courier_wave_start_lng','courier_wave_start_lat',\n",
    "                   'action_type','expect_time','date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "mae=200\n",
    "os.makedirs('./sub/{}'.format(int(mae)), exist_ok=True)\n",
    "f = zipfile.ZipFile('./sub/{}.zip'.format(int(mae)), 'w', zipfile.ZIP_DEFLATED)\n",
    "for date in prediction['date'].unique():\n",
    "    df_temp = prediction[prediction['date'] == date]\n",
    "    del df_temp['date']\n",
    "    df_temp.to_csv('./sub/{}/action_{}.txt'.format(int(mae), date), index=False)\n",
    "    f.write('./sub/{}/action_{}.txt'.format(int(mae), date), 'action_{}.txt'.format(date))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testA['pred']=model_final.predict(df_testA[df_feature_name])\n",
    "same_track_id=df_testA.groupby('tracking_id').size()[df_testA.groupby('tracking_id').size()==2].reset_index()['tracking_id'].values.tolist()\n",
    "df_testA_afterchoice=df_testA[~((df_testA['tracking_id'].isin(same_track_id)) & (df_testA['action_type']==0))]\n",
    "maxid=df_testA_afterchoice.groupby('group')['pred'].idxmax()\n",
    "df_testA['target']=0\n",
    "df_testA.loc[maxid,'target']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_testA=pd.concat([df_train,df_testA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycol = 'target'\n",
    "feature_names = df_feature_name\n",
    "params = {\n",
    "    'num_leaves':31,\n",
    "    'n_estimators': 10000,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'is_unbalance':'true',\n",
    "    'metrics':'group_acc',\n",
    "    'early_stopping_rounds': 50,\n",
    "    'num_threads':20,\n",
    "    'seed':513\n",
    "}\n",
    "\n",
    "oof = []\n",
    "prediction = df_test[['id', 'group']]\n",
    "prediction['target'] = 0\n",
    "df_importance_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[10]\tvalid_0's group_acc: 0.821843\n",
      "[20]\tvalid_0's group_acc: 0.823788\n",
      "[30]\tvalid_0's group_acc: 0.828543\n",
      "[40]\tvalid_0's group_acc: 0.83092\n",
      "[50]\tvalid_0's group_acc: 0.832721\n",
      "[60]\tvalid_0's group_acc: 0.833225\n",
      "[70]\tvalid_0's group_acc: 0.835314\n",
      "[80]\tvalid_0's group_acc: 0.835963\n",
      "[90]\tvalid_0's group_acc: 0.836467\n",
      "[100]\tvalid_0's group_acc: 0.83726\n",
      "[110]\tvalid_0's group_acc: 0.837476\n",
      "[120]\tvalid_0's group_acc: 0.836755\n",
      "[130]\tvalid_0's group_acc: 0.837043\n",
      "[140]\tvalid_0's group_acc: 0.837115\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's group_acc: 0.837548\n",
      "========================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[10]\tvalid_0's group_acc: 0.817592\n",
      "[20]\tvalid_0's group_acc: 0.823716\n",
      "[30]\tvalid_0's group_acc: 0.827462\n",
      "[40]\tvalid_0's group_acc: 0.830272\n",
      "[50]\tvalid_0's group_acc: 0.83409\n",
      "[60]\tvalid_0's group_acc: 0.836971\n",
      "[70]\tvalid_0's group_acc: 0.838052\n",
      "[80]\tvalid_0's group_acc: 0.8387\n",
      "[90]\tvalid_0's group_acc: 0.839349\n",
      "[100]\tvalid_0's group_acc: 0.839853\n",
      "[110]\tvalid_0's group_acc: 0.840429\n",
      "[120]\tvalid_0's group_acc: 0.841078\n",
      "[130]\tvalid_0's group_acc: 0.839925\n",
      "[140]\tvalid_0's group_acc: 0.840285\n",
      "[150]\tvalid_0's group_acc: 0.839853\n",
      "[160]\tvalid_0's group_acc: 0.840285\n",
      "[170]\tvalid_0's group_acc: 0.840285\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's group_acc: 0.841078\n",
      "========================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[10]\tvalid_0's group_acc: 0.823343\n",
      "[20]\tvalid_0's group_acc: 0.826297\n",
      "[30]\tvalid_0's group_acc: 0.831052\n",
      "[40]\tvalid_0's group_acc: 0.83415\n",
      "[50]\tvalid_0's group_acc: 0.836888\n",
      "[60]\tvalid_0's group_acc: 0.83768\n",
      "[70]\tvalid_0's group_acc: 0.839481\n",
      "[80]\tvalid_0's group_acc: 0.840418\n",
      "[90]\tvalid_0's group_acc: 0.841354\n",
      "[100]\tvalid_0's group_acc: 0.841859\n",
      "[110]\tvalid_0's group_acc: 0.842363\n",
      "[120]\tvalid_0's group_acc: 0.843012\n",
      "[130]\tvalid_0's group_acc: 0.84366\n",
      "[140]\tvalid_0's group_acc: 0.843732\n",
      "[150]\tvalid_0's group_acc: 0.843588\n",
      "[160]\tvalid_0's group_acc: 0.843228\n",
      "[170]\tvalid_0's group_acc: 0.843444\n",
      "[180]\tvalid_0's group_acc: 0.843876\n",
      "[190]\tvalid_0's group_acc: 0.844164\n",
      "[200]\tvalid_0's group_acc: 0.844236\n",
      "[210]\tvalid_0's group_acc: 0.843804\n",
      "[220]\tvalid_0's group_acc: 0.843804\n",
      "[230]\tvalid_0's group_acc: 0.844092\n",
      "[240]\tvalid_0's group_acc: 0.843804\n",
      "[250]\tvalid_0's group_acc: 0.844164\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's group_acc: 0.844597\n",
      "========================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[10]\tvalid_0's group_acc: 0.820389\n",
      "[20]\tvalid_0's group_acc: 0.825865\n",
      "[30]\tvalid_0's group_acc: 0.829467\n",
      "[40]\tvalid_0's group_acc: 0.832133\n",
      "[50]\tvalid_0's group_acc: 0.834078\n",
      "[60]\tvalid_0's group_acc: 0.836311\n",
      "[70]\tvalid_0's group_acc: 0.838256\n",
      "[80]\tvalid_0's group_acc: 0.838833\n",
      "[90]\tvalid_0's group_acc: 0.839914\n",
      "[100]\tvalid_0's group_acc: 0.840922\n",
      "[110]\tvalid_0's group_acc: 0.840058\n",
      "[120]\tvalid_0's group_acc: 0.839986\n",
      "[130]\tvalid_0's group_acc: 0.84049\n",
      "[140]\tvalid_0's group_acc: 0.840778\n",
      "[150]\tvalid_0's group_acc: 0.840922\n",
      "[160]\tvalid_0's group_acc: 0.840994\n",
      "[170]\tvalid_0's group_acc: 0.841066\n",
      "[180]\tvalid_0's group_acc: 0.840562\n",
      "[190]\tvalid_0's group_acc: 0.840562\n",
      "[200]\tvalid_0's group_acc: 0.84049\n",
      "[210]\tvalid_0's group_acc: 0.840706\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's group_acc: 0.841282\n",
      "========================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[10]\tvalid_0's group_acc: 0.81866\n",
      "[20]\tvalid_0's group_acc: 0.825432\n",
      "[30]\tvalid_0's group_acc: 0.829611\n",
      "[40]\tvalid_0's group_acc: 0.832421\n",
      "[50]\tvalid_0's group_acc: 0.83451\n",
      "[60]\tvalid_0's group_acc: 0.834726\n",
      "[70]\tvalid_0's group_acc: 0.836239\n",
      "[80]\tvalid_0's group_acc: 0.837248\n",
      "[90]\tvalid_0's group_acc: 0.837824\n",
      "[100]\tvalid_0's group_acc: 0.838256\n",
      "[110]\tvalid_0's group_acc: 0.838905\n",
      "[120]\tvalid_0's group_acc: 0.839481\n",
      "[130]\tvalid_0's group_acc: 0.839841\n",
      "[140]\tvalid_0's group_acc: 0.839409\n",
      "[150]\tvalid_0's group_acc: 0.839265\n",
      "[160]\tvalid_0's group_acc: 0.839914\n",
      "[170]\tvalid_0's group_acc: 0.839769\n",
      "[180]\tvalid_0's group_acc: 0.840202\n",
      "[190]\tvalid_0's group_acc: 0.840202\n",
      "[200]\tvalid_0's group_acc: 0.839986\n",
      "[210]\tvalid_0's group_acc: 0.839841\n",
      "[220]\tvalid_0's group_acc: 0.839697\n",
      "[230]\tvalid_0's group_acc: 0.839337\n",
      "[240]\tvalid_0's group_acc: 0.839049\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid_0's group_acc: 0.840418\n",
      "========================================\n",
      "acc: 0.8451296829971181\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "def wave_group_func(group):\n",
    "    target_list = group['label'].values.tolist()\n",
    "    pred_list = group['pred'].values.tolist()\n",
    "    max_index = pred_list.index(max(pred_list))\n",
    "    if target_list[max_index] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def group_acc(preds,dtrain):\n",
    "    label=dtrain.get_label()\n",
    "    pred_list=pd.DataFrame({'group':val_group,\n",
    "                            'pred':preds,\n",
    "                            'label':label})\n",
    "    df_temp =pred_list.groupby(['group']).apply(wave_group_func).reset_index()\n",
    "    df_temp.columns = ['group', 'label']\n",
    "    acc = df_temp[df_temp['label'] == 1].shape[0] / df_temp.shape[0]\n",
    "    return 'group_acc',float(acc),True\n",
    "\n",
    "kfold = GroupKFold(n_splits=5)\n",
    "kfold_in = GroupKFold(n_splits=5)\n",
    "for fold_id, (trn_idx, val_idx) in enumerate(kfold.split(df_train_testA[feature_names], df_train_testA[ycol], df_train_testA['group'])):\n",
    "    X_train = df_train_testA.iloc[trn_idx][feature_names+['group']]\n",
    "    Y_train = df_train_testA.iloc[trn_idx][ycol]\n",
    "    X_val = df_train_testA.iloc[val_idx][feature_names+['group']]\n",
    "    Y_val = df_train_testA.iloc[val_idx][ycol]\n",
    "    groupp=df_train_testA.iloc[val_idx]['group'].values\n",
    "    pred_val=np.zeros(X_val.shape[0])\n",
    "if 1:\n",
    "    for fold_in_id, (train_in_idx, val_in_idx) in enumerate(kfold_in.split(X_train, Y_train, X_train['group'])):\n",
    "        val_group=X_train['group'].iloc[val_in_idx]\n",
    "        train_set = lgb.Dataset(X_train.drop(columns='group').iloc[train_in_idx], Y_train.iloc[train_in_idx])\n",
    "        val_set = lgb.Dataset(X_train.drop(columns='group').iloc[val_in_idx], Y_train.iloc[val_in_idx])\n",
    "        model = lgb.train(params, train_set,valid_sets=val_set,\n",
    "                          categorical_feature=['weather_grade','current_hour_bin'],\n",
    "                          feval=group_acc,verbose_eval=10)\n",
    "        pred_test = model.predict(X_val.drop(columns='group'))\n",
    "        \n",
    "        df_importance = pd.DataFrame({\n",
    "        'column': model.feature_name(),\n",
    "        'importance': model.feature_importance('gain')})\n",
    "        df_importance_list.append(df_importance)\n",
    "        pred_val += pred_test / 5\n",
    "        print('========================================')\n",
    "    pred_df = pd.DataFrame({'group':groupp,\n",
    "                                'pred':pred_val,\n",
    "                                'label':Y_val.values})\n",
    "    df_temp = pred_df.groupby(['group']).apply(wave_group_func).reset_index()\n",
    "    df_temp.columns = ['group', 'label']\n",
    "    acc = df_temp[df_temp['label'] == 1].shape[0] / df_temp.shape[0]\n",
    "    print('acc:', acc)\n",
    "    print('=======================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves':31,\n",
    "    'n_estimators': 200,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'is_unbalance':'true',\n",
    "    'objective': 'binary',\n",
    "    'num_threads':20\n",
    "}\n",
    "train_set = lgb.Dataset(df_train_testA[df_feature_name], df_train_testA['target'])\n",
    "model_final = lgb.train(params,train_set,\n",
    "                        categorical_feature=['weather_grade','current_hour_bin'],)\n",
    "pred=model_final.predict(df_test[df_feature_name])\n",
    "df_test['pred']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_track_id=df_test.groupby('tracking_id').size()[df_test.groupby('tracking_id').size()==2].reset_index()['tracking_id'].values.tolist()\n",
    "df_test_afterchoice=df_test[~((df_test['tracking_id'].isin(same_track_id)) & (df_test['action_type']==0))]\n",
    "maxid=df_test_afterchoice.groupby('group')['pred'].idxmax()\n",
    "df_sub=copy.deepcopy(df_test_afterchoice.loc[maxid])\n",
    "df_sub.loc[df_sub['action_type']==0,'action_type']='DELIVERY'\n",
    "df_sub.loc[df_sub['action_type']==1,'action_type']='PICKUP'\n",
    "prediction=df_sub[['courier_id','wave_index','tracking_id','courier_wave_start_lng','courier_wave_start_lat',\n",
    "                   'action_type','expect_time','date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "mae=415\n",
    "os.makedirs('./sub/{}'.format(int(mae)), exist_ok=True)\n",
    "f = zipfile.ZipFile('./sub/{}.zip'.format(int(mae)), 'w', zipfile.ZIP_DEFLATED)\n",
    "for date in prediction['date'].unique():\n",
    "    df_temp = prediction[prediction['date'] == date]\n",
    "    del df_temp['date']\n",
    "    df_temp.to_csv('./sub/{}/action_{}.txt'.format(int(mae), date), index=False)\n",
    "    f.write('./sub/{}/action_{}.txt'.format(int(mae), date), 'action_{}.txt'.format(date))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
