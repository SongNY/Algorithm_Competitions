### 方案简介

- 从pdf中提取所有字符，相互临近的字符拼接成字符串，提取字符串其位置、文本信息。
- 开始把字符串归到行，并预处理因换行而被切开的字符串。
- 判断简历是否左右分栏，如有左右边栏，将较窄部分放入side。(左右边栏称作边栏，剩余部分称作主部分)
- 定位主部分的简历副标题(section title)，比如工作经历/项目经验/教育背景等，将简历划分为四大块包括：base;edu;job;project 。如果主部分没有标题，或某部分没有提取到，将简历字符串文本信息按边栏+主部分顺序输入bert-lstm-crf模型进行预测分块。
- 基本信息(base)：预处理后把所有字符串用 | 作为分隔符拼到一个字符串里，再进行正则提取。
- 教育信息(edu)：首先匹配日期范围，正则匹配学校以及学位。
- 工作信息(job)：首先找到工作经历的所有日期范围。以每个日期范围为基准，在日期范围所在行的附近正则匹配寻找公司、寻找职位名称。工作经历所有内容去掉日期、公司、职位，以及(工作描述：/:)的标题，中间全部放入职位描述。
- 项目信息(project)：首先找到项目经历的所有日期范围。以每个日期范围为基准，在日期范围所在行的附近匹配项目名称，项目经历所有内容去掉日期、名称，以及(项目描述：/:)的标题，中间全部放入项目描述。
- Bert-lstm-crf模型：用以辅助将简历划分为四大块。

  - 训练部分：对于每个简历文档，
    - 将提取到的字符串以从上至下、从左至右的顺序，形成输入序列，使用BERT进行embedding；
    - 用先前提到的规则方法（定位section title将简历分块），将所标注好的结果作为这些输入的label；
    - 输入到lstm-crf网络进行训练。
  - 预测部分：对于每个简历文档，
    - 将提取到的字符串以从上至下、从左至右的顺序，形成输入序列，使用BERT进行embedding；
    - 输入到lstm-crf网络进行预测。



### 代码结构说明

- `start-bert-as-service.py`: 开启bert-servise
- `train.py`: 产生bert-lstm-crf模型
- `main.py`: 完成预测 输出test_result.json

### 复现过程

- 配置好环境，运行 `main.sh` 即可。


#### need
/user_data/model_data//chinese_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001